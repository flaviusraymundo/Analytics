{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "60905926",
      "metadata": {
        "id": "60905926"
      },
      "source": [
        "\n",
        "# Relatório Individual — v8\n",
        "- Une a estrutura da v6/v7.2 com o gerador de texto da v7.1.\n",
        "- Se os helpers da v7.1 não forem detectados, usa o texto heurístico completo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4bbedb",
      "metadata": {
        "id": "dd4bbedb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Config ===\n",
        "SPREADSHEET_INPUT_ID  = \"COLOQUE_AQUI\"   # planilha do site (Leads_Clean)\n",
        "SPREADSHEET_OUTPUT_ID = \"COLOQUE_AQUI\"   # planilha destino das abas REL_*\n",
        "\n",
        "# Sessão alvo (defina um). Se ambos None, usa a última selection_final.\n",
        "SESSION_EFFECTIVE = None                 # ex.: \"1ba80cbd-...\"\n",
        "EVENT_ID         = None                  # ex.: \"evt_...\"\n",
        "\n",
        "# Catálogo com atributos\n",
        "CAT_PATHS = [\n",
        "    \"data/essencias_88_enriquecido.json\",\n",
        "    \"/content/data/essencias_88_enriquecido.json\",\n",
        "]\n",
        "\n",
        "# Texto\n",
        "TEXT_MODE    = \"heuristic\"  # \"heuristic\" | \"llm\" | \"llm_editor\" | \"v7_1\"\n",
        "LLM_PROVIDER = \"openai\"\n",
        "LLM_MODEL    = \"gpt-4o-mini\"\n",
        "LLM_API_KEY  = None\n",
        "LLM_API_URL  = None\n",
        "\n",
        "# Gravação mínima\n",
        "TEXT_ONLY = False           # True => só REL_TEXT e REL_DETALHES_TODAS\n",
        "\n",
        "# Abas\n",
        "TAB_OVERVIEW    = \"REL_OVERVIEW\"\n",
        "TAB_PRE_POS     = \"REL_PRE_POS\"\n",
        "TAB_PRE_NEG     = \"REL_PRE_NEG\"\n",
        "TAB_FINAL_POS   = \"REL_FINAL_POS\"\n",
        "TAB_FINAL_NEG   = \"REL_FINAL_NEG\"\n",
        "TAB_MOVEMENT    = \"REL_MOVEMENT\"\n",
        "TAB_COMPARATIVO = \"REL_COMPARATIVO\"\n",
        "TAB_RESUMO      = \"REL_RESUMO\"\n",
        "TAB_TEMPORAL    = \"REL_TEMPORAL\"\n",
        "TAB_PRODUTO     = \"REL_PRODUTO\"\n",
        "TAB_TEXT        = \"REL_TEXT\"\n",
        "\n",
        "TAB_DET_PRE_POS = \"REL_DETALHES_PRE_POS\"\n",
        "TAB_DET_PRE_NEG = \"REL_DETALHES_PRE_NEG\"\n",
        "TAB_DET_FIN_POS = \"REL_DETALHES_FINAL_POS\"\n",
        "TAB_DET_FIN_NEG = \"REL_DETALHES_FINAL_NEG\"\n",
        "TAB_DET_ALL     = \"REL_DETALHES_TODAS\"\n",
        "TAB_ATTRS       = \"REL_ATTRS\"\n",
        "TAB_ATTRS_STAGE = \"REL_ATTRS_STAGE\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ef8738",
      "metadata": {
        "id": "c6ef8738"
      },
      "outputs": [],
      "source": [
        "%pip -q install gspread gspread_dataframe pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9da6ead",
      "metadata": {
        "id": "f9da6ead"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Autenticação e abertura ===\n",
        "import gspread, json, pandas as pd, numpy as np, unicodedata, re, requests, os\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\",\n",
        "          \"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "try:\n",
        "    from google.colab import auth as colab_auth\n",
        "    colab_auth.authenticate_user()\n",
        "    import google.auth\n",
        "    creds, _ = google.auth.default(scopes=SCOPES)\n",
        "    gc = gspread.authorize(creds)\n",
        "except Exception as e:\n",
        "    raise SystemExit(f\"Falha de autenticação: {e}\")\n",
        "\n",
        "assert SPREADSHEET_INPUT_ID  != \"COLOQUE_AQUI\",  \"Defina SPREADSHEET_INPUT_ID.\"\n",
        "assert SPREADSHEET_OUTPUT_ID != \"COLOQUE_AQUI\", \"Defina SPREADSHEET_OUTPUT_ID.\"\n",
        "\n",
        "ss_in  = gc.open_by_key(SPREADSHEET_INPUT_ID)\n",
        "ss_out = gc.open_by_key(SPREADSHEET_OUTPUT_ID)\n",
        "print(\"OK: planilhas abertas.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2614946",
      "metadata": {
        "id": "d2614946"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Utils ===\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "def _norm(s:str)->str:\n",
        "    s = str(s or \"\").strip().lower()\n",
        "    s = \"\".join(c for c in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(c))\n",
        "    s = re.sub(r\"[^a-z0-9\\s\\-\\_]\", \"\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def build_alias_map_from_json(path: Path):\n",
        "    data = json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "    items = data if isinstance(data, list) else data.get(\"items\", [])\n",
        "    alias = {}\n",
        "    for it in items:\n",
        "        eid = it.get(\"id\") or _norm(it.get(\"name\"))\n",
        "        names = [it.get(\"name\",\"\")] + it.get(\"aliases\", [])\n",
        "        for n in names:\n",
        "            alias[_norm(n)] = eid\n",
        "    return alias\n",
        "\n",
        "def load_catalog_df():\n",
        "    for p in CAT_PATHS:\n",
        "        pth = Path(p)\n",
        "        if pth.exists():\n",
        "            data = json.loads(pth.read_text(encoding=\"utf-8\"))\n",
        "            cat = pd.DataFrame(data if isinstance(data, list) else data.get(\"items\", []))\n",
        "            if \"id\" not in cat.columns and \"essence_id\" in cat.columns: cat[\"id\"] = cat[\"essence_id\"]\n",
        "            for src,dst in {\"cor\":\"color\",\"chakra\":\"chakra\",\"camada\":\"camada\",\"arquetipo\":\"arquetipo\",\"dominio\":\"dominio\"}.items():\n",
        "                if dst not in cat.columns and src in cat.columns:\n",
        "                    cat[dst] = cat[src]\n",
        "            cat[\"id_norm\"] = cat[\"id\"].astype(str).str.lower()\n",
        "            keep = [c for c in [\"id_norm\",\"color\",\"chakra\",\"camada\",\"arquetipo\",\"dominio\"] if c in cat.columns]\n",
        "            return cat[keep]\n",
        "    return None\n",
        "\n",
        "def parse_selection_both(sel):\n",
        "    parts = [p.strip() for p in str(sel or \"\").split(\"|\") if p.strip()]\n",
        "    pos = [p[3:].strip() for p in parts if p.startswith(\"(+)\")]\n",
        "    neg = [p[3:].strip() for p in parts if p.startswith(\"(-)\")]\n",
        "    return pos, neg\n",
        "\n",
        "def write_tab(ss, name, df):\n",
        "    try:\n",
        "        ws = ss.worksheet(name); ws.clear()\n",
        "    except Exception:\n",
        "        rows = max(100, (len(df)+10) if df is not None else 100)\n",
        "        ws = ss.add_worksheet(title=name, rows=str(rows), cols=\"50\")\n",
        "    if df is None or len(df)==0: df = pd.DataFrame([{\"info\":\"sem dados\"}])\n",
        "    set_with_dataframe(ws, df.reset_index(drop=True), include_index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2343a5bb",
      "metadata": {
        "id": "2343a5bb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Leitura (stage ← kind) ===\n",
        "def read_leads(spreadsheet, tab=\"Leads_Clean\"):\n",
        "    ws = spreadsheet.worksheet(tab)\n",
        "    df = get_as_dataframe(ws, evaluate_formulas=True, header=0).dropna(how=\"all\")\n",
        "    if \"stage\" not in df.columns:\n",
        "        if \"kind\" in df.columns:\n",
        "            k = df[\"kind\"].astype(str).str.lower()\n",
        "            df[\"stage\"] = k.where(k.isin([\"preselection\",\"selection_final\"]), \"\")\n",
        "        else:\n",
        "            df[\"stage\"] = \"\"\n",
        "    for c in [\"stage\",\"mode\",\"tenant_id\",\"team\"]:\n",
        "        if c in df.columns: df[c] = df[c].astype(str).str.lower()\n",
        "    df = df[df[\"stage\"].isin([\"preselection\",\"selection_final\"])].copy()\n",
        "    if \"timestamp_local\" in df.columns:\n",
        "        df[\"timestamp_local\"] = pd.to_datetime(df[\"timestamp_local\"], errors=\"coerce\")\n",
        "    if \"selection_count\" in df.columns:\n",
        "        df[\"selection_count\"] = pd.to_numeric(df[\"selection_count\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "    return df\n",
        "\n",
        "raw = read_leads(ss_in)\n",
        "print(\"Linhas válidas:\", len(raw))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe0f00f9",
      "metadata": {
        "id": "fe0f00f9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Resolver sessão ===\n",
        "def resolve_session(df, SESSION_EFFECTIVE=None, EVENT_ID=None):\n",
        "    if SESSION_EFFECTIVE:\n",
        "        s = str(SESSION_EFFECTIVE).strip()\n",
        "        if (df[\"session_effective\"]==s).any():\n",
        "            return s\n",
        "        if \"event_id_linked\" in df.columns and (df[\"event_id_linked\"]==s).any():\n",
        "            return df.loc[df[\"event_id_linked\"]==s, \"session_effective\"].iloc[0]\n",
        "    if EVENT_ID and \"event_id_linked\" in df.columns:\n",
        "        e = str(EVENT_ID).strip()\n",
        "        if (df[\"event_id_linked\"]==e).any():\n",
        "            return df.loc[df[\"event_id_linked\"]==e, \"session_effective\"].iloc[0]\n",
        "    cand = df[df[\"stage\"]==\"selection_final\"].sort_values(\"timestamp_local\").tail(1)\n",
        "    if len(cand):\n",
        "        return cand[\"session_effective\"].iloc[0]\n",
        "    raise ValueError(\"Nenhuma sessão encontrada. Defina SESSION_EFFECTIVE ou EVENT_ID.\")\n",
        "\n",
        "SESS = resolve_session(raw, SESSION_EFFECTIVE, EVENT_ID)\n",
        "print(\"Sessão alvo:\", SESS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e203b2",
      "metadata": {
        "id": "88e203b2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Extrair, normalizar e enriquecer ===\n",
        "from pathlib import Path\n",
        "alias_map = {}\n",
        "for p in CAT_PATHS:\n",
        "    pth = Path(p)\n",
        "    if pth.exists():\n",
        "        alias_map = build_alias_map_from_json(pth); break\n",
        "CAT = load_catalog_df()\n",
        "\n",
        "d = raw[raw[\"session_effective\"]==SESS].copy()\n",
        "pre  = d[d[\"stage\"]==\"preselection\"].sort_values(\"timestamp_local\").tail(1)\n",
        "fin  = d[d[\"stage\"]==\"selection_final\"].sort_values(\"timestamp_local\").tail(1)\n",
        "\n",
        "def expand_rows(row, stage):\n",
        "    pos, neg = parse_selection_both(row.get(\"selection\"))\n",
        "    recs = []\n",
        "    for name in pos: recs.append({\"stage\": stage, \"valence\":\"positive\", \"essence_name\": name})\n",
        "    for name in neg: recs.append({\"stage\": stage, \"valence\":\"negative\", \"essence_name\": name})\n",
        "    return pd.DataFrame.from_records(recs) if recs else pd.DataFrame(columns=[\"stage\",\"valence\",\"essence_name\"])\n",
        "\n",
        "pre_rows = expand_rows(pre.iloc[0] if len(pre) else {}, \"preselection\")\n",
        "fin_rows = expand_rows(fin.iloc[0] if len(fin) else {}, \"selection_final\")\n",
        "\n",
        "def normalize_names(df_names):\n",
        "    if df_names is None or df_names.empty: return df_names\n",
        "    if alias_map:\n",
        "        df_names = df_names.assign(essence_id=df_names[\"essence_name\"].map(lambda x: alias_map.get(_norm(x), _norm(x))))\n",
        "    else:\n",
        "        df_names = df_names.assign(essence_id=df_names[\"essence_name\"].map(_norm))\n",
        "    return df_names\n",
        "\n",
        "pre_rows  = normalize_names(pre_rows)\n",
        "fin_rows  = normalize_names(fin_rows)\n",
        "\n",
        "pre_pos   = pre_rows[pre_rows[\"valence\"]==\"positive\"][[\"essence_id\",\"essence_name\"]]\n",
        "pre_neg   = pre_rows[pre_rows[\"valence\"]==\"negative\"][[\"essence_id\",\"essence_name\"]]\n",
        "final_pos = fin_rows[fin_rows[\"valence\"]==\"positive\"][[\"essence_id\",\"essence_name\"]]\n",
        "final_neg = fin_rows[fin_rows[\"valence\"]==\"negative\"][[\"essence_id\",\"essence_name\"]]\n",
        "\n",
        "preP, preN = set(pre_pos[\"essence_id\"]), set(pre_neg[\"essence_id\"])\n",
        "finP, finN = set(final_pos[\"essence_id\"]), set(final_neg[\"essence_id\"])\n",
        "rows = []\n",
        "for e in sorted(preP | preN | finP | finN):\n",
        "    rows.append({\n",
        "        \"essence_id\": e,\n",
        "        \"pre\":  \"+\" if e in preP else (\"-\" if e in preN else \"\"),\n",
        "        \"final\":\"+\"\" if e in finP else (\"-\" if e in finN else \"\"),\n",
        "        \"pp\": int(e in preP and e in finP),\n",
        "        \"pn\": int(e in preP and e not in finP),\n",
        "        \"np\": int(e in preN and e in finP),\n",
        "        \"nn\": int(e in preN and e in finN),\n",
        "    })\n",
        "comparativo = pd.DataFrame(rows)\n",
        "mov_cols = [\"pp\",\"pn\",\"np\",\"nn\"]\n",
        "comparativo[\"movement\"] = comparativo.apply(lambda r: \"++\" if r[\"pp\"] else (\"+-\" if r[\"pn\"] else (\"-+\" if r[\"np\"] else (\"--\" if r[\"nn\"] else (r[\"pre\"]+'0' if r[\"pre\"] else ('0'+r[\"final\"] if r[\"final\"] else '0'))))), axis=1)\n",
        "movement = comparativo[[\"essence_id\"] + mov_cols + [\"movement\"]].sort_values(mov_cols, ascending=[False, True, True, True])\n",
        "\n",
        "meta_cols = [\"timestamp_local\",\"tenant_id\",\"team\",\"mode\",\"selection_count\",\"name\",\"email\",\"phone\",\"origin\",\"utm_source\",\"utm_medium\",\"utm_campaign\"]\n",
        "overview = d.sort_values(\"timestamp_local\").tail(1)\n",
        "overview = overview[[c for c in meta_cols if c in overview.columns]].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0c2e3e0",
      "metadata": {
        "id": "b0c2e3e0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Detalhes por flor com atributos ===\n",
        "def enrich_with_attrs(df_tab):\n",
        "    if df_tab is None or df_tab.empty: return df_tab\n",
        "    out = df_tab.copy()\n",
        "    out[\"id_norm\"] = out[\"essence_id\"].astype(str).str.lower()\n",
        "    if CAT is not None: out = out.merge(CAT, on=\"id_norm\", how=\"left\")\n",
        "    cols_pref = [\"stage\",\"valence\",\"essence_id\",\"essence_name\",\"color\",\"chakra\",\"camada\",\"arquetipo\",\"dominio\"]\n",
        "    cols = [c for c in cols_pref if c in out.columns] + [c for c in out.columns if c not in cols_pref+[\"id_norm\"]]\n",
        "    return out[cols]\n",
        "\n",
        "pre_pos_e = enrich_with_attrs(pre_rows[pre_rows[\"valence\"]==\"positive\"])\n",
        "pre_neg_e = enrich_with_attrs(pre_rows[pre_rows[\"valence\"]==\"negative\"])\n",
        "fin_pos_e = enrich_with_attrs(fin_rows[fin_rows[\"valence\"]==\"positive\"])\n",
        "fin_neg_e = enrich_with_attrs(fin_rows[fin_rows[\"valence\"]==\"negative\"])\n",
        "\n",
        "det_all = pd.concat([pre_pos_e, pre_neg_e, fin_pos_e, fin_neg_e], ignore_index=True)\n",
        "stage_order = {\"preselection\":0, \"selection_final\":1}\n",
        "val_order = {\"positive\":0, \"negative\":1}\n",
        "if len(det_all):\n",
        "    det_all = det_all.assign(_s=det_all[\"stage\"].map(stage_order), _v=det_all[\"valence\"].map(val_order)) \\\n",
        "                     .sort_values([\"_s\",\"_v\",\"essence_name\"]).drop(columns=[\"_s\",\"_v\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1287d0ae",
      "metadata": {
        "id": "1287d0ae"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Contagens de atributos ===\n",
        "def count_attrs(df, kind_label):\n",
        "    rows = []\n",
        "    if df is None or len(df)==0: return pd.DataFrame(columns=[\"kind\",\"attr\",\"value\",\"count\"])\n",
        "    for attr in [\"color\",\"chakra\",\"camada\",\"arquetipo\",\"dominio\"]:\n",
        "        if attr in df.columns:\n",
        "            cnt = Counter(df[attr].dropna().astype(str).tolist())\n",
        "            for k,v in cnt.items(): rows.append({\"kind\": kind_label, \"attr\": attr, \"value\": k, \"count\": v})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "REL_ATTRS_STAGE = pd.concat([\n",
        "    count_attrs(pre_pos_e,   \"pre_pos\"),\n",
        "    count_attrs(pre_neg_e,   \"pre_neg\"),\n",
        "    count_attrs(fin_pos_e,   \"final_pos\"),\n",
        "    count_attrs(fin_neg_e,   \"final_neg\"),\n",
        "], ignore_index=True)\n",
        "\n",
        "def top3_overall(df_counts):\n",
        "    if df_counts is None or len(df_counts)==0: return pd.DataFrame([{\"attr\":\"info\",\"value\":\"sem dados\"}])\n",
        "    rows = []\n",
        "    for attr in [\"color\",\"chakra\",\"camada\",\"arquetipo\",\"dominio\"]:\n",
        "        sub = df_counts[df_counts[\"attr\"]==attr].groupby(\"value\")[\"count\"].sum().sort_values(ascending=False).head(3)\n",
        "        if len(sub): rows.append({\"attr\": f\"{attr}_top3\", \"value\": \", \".join([f\"{k}({v})\" for k,v in sub.items()])})\n",
        "    return pd.DataFrame(rows) if rows else pd.DataFrame([{\"attr\":\"info\",\"value\":\"sem dados\"}])\n",
        "\n",
        "REL_ATTRS = top3_overall(REL_ATTRS_STAGE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a078eea2",
      "metadata": {
        "id": "a078eea2"
      },
      "source": [
        "### Helpers da v7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b090da6d",
      "metadata": {
        "id": "b090da6d"
      },
      "outputs": [],
      "source": [
        "import os, json, re, unicodedata\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "CATALOG_PATHS = [\n",
        "    \"/mnt/data/essencias_88_enriquecido.json\",\n",
        "    \"/mnt/data/essencias_88.json\",\n",
        "]\n",
        "\n",
        "def _slugify(name: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKD\", name)\n",
        "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
        "    s = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", s).strip(\"_\").lower()\n",
        "    return s\n",
        "\n",
        "def load_catalog() -> Dict[str, Dict[str, Any]]:\n",
        "    for p in CATALOG_PATHS:\n",
        "        if os.path.exists(p):\n",
        "            with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "                items = json.load(f)\n",
        "            return {it[\"id\"]: it for it in items}\n",
        "    return {}\n",
        "\n",
        "CATALOG = load_catalog()\n",
        "\n",
        "def map_name_to_id(name: str) -> str:\n",
        "    slug = _slugify(name)\n",
        "    if slug in CATALOG:\n",
        "        return slug\n",
        "    for k, m in CATALOG.items():\n",
        "        if m.get(\"nome\",\"\").strip().lower() == name.strip().lower():\n",
        "            return k\n",
        "    for k, m in CATALOG.items():\n",
        "        if _slugify(m.get(\"nome\",\"\")) == slug:\n",
        "            return k\n",
        "    return slug\n",
        "\n",
        "def safe_meta(eid: str) -> Dict[str, Any]:\n",
        "    m = CATALOG.get(eid)\n",
        "    if m: return m\n",
        "    return {\"id\": eid, \"nome\": eid, \"camada\": [], \"familia\": \"\", \"cor\": [], \"chakras\": [], \"arquetipos\": [], \"funcoes\": []}\n",
        "\n",
        "def parse_selection(selection_str: str) -> List[Tuple[str,int]]:\n",
        "    if not isinstance(selection_str, str) or not selection_str.strip():\n",
        "        return []\n",
        "    parts = [p.strip() for p in selection_str.split(\"|\")]\n",
        "    out = []\n",
        "    for p in parts:\n",
        "        m = re.match(r\"^\\((\\+|\\-)\\)\\s*(.+?)\\s*$\", p)\n",
        "        if not m:\n",
        "            sign = +1; name = p\n",
        "        else:\n",
        "            sign = +1 if m.group(1) == \"+\" else -1\n",
        "            name = m.group(2)\n",
        "        eid = map_name_to_id(name)\n",
        "        out.append((eid, sign))\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "REL_FAMILIAS = set([\"Kangaroo Paw\"])\n",
        "TRIGGER_FAMILIAS = set([\"Triggerplant\"])\n",
        "PROF_IDS = set([\"christmas_tree\",\"balga_blackboy\",\"goddess_grasstree\",\"macrozamia\",\"ursinia\"])\n",
        "C5_IDS = set([\"wa_smokebush\",\"leafless_orchid\",\"red_beak_orchid\",\"pink_trumpet_flower\",\"purple_enamel_orchid\"])\n",
        "\n",
        "def _sum_list(vals):\n",
        "    acc = {}\n",
        "    for v in vals: acc[v] = acc.get(v,0)+1\n",
        "    return acc\n",
        "\n",
        "def build_metrics(ids):\n",
        "    metas = [safe_meta(x) for x in ids]\n",
        "    camadas = [c for m in metas for c in (m.get(\"camada\") or [])]\n",
        "    cores   = [c for m in metas for c in (m.get(\"cor\") or [])]\n",
        "    chak    = [c for m in metas for c in (m.get(\"chakras\") or [])]\n",
        "    Ccount = _sum_list(camadas)\n",
        "    coreCount = _sum_list(cores)\n",
        "    chCount = _sum_list(chak)\n",
        "    IR = sum(1 for m in metas if \"H\" in (m.get(\"camada\") or []) or (m.get(\"familia\")==\"Kangaroo Paw\"))\n",
        "    IP = sum(1 for m in metas if \"P\" in (m.get(\"camada\") or []) or (m.get(\"id\") in PROF_IDS))\n",
        "    IE = sum(1 for m in metas if (m.get(\"familia\") in TRIGGER_FAMILIAS) or (m.get(\"id\") in C5_IDS) or (\"C5\" in (m.get(\"camada\") or [])))\n",
        "    return {\n",
        "        \"I_C1\": Ccount.get(\"C1\",0),\"I_C2\": Ccount.get(\"C2\",0),\"I_C3\": Ccount.get(\"C3\",0),\"I_C4\": Ccount.get(\"C4\",0),\"I_C5\": Ccount.get(\"C5\",0),\n",
        "        \"IR\": IR, \"IP\": IP, \"IE\": IE, \"cores\": coreCount, \"chakras\": chCount, \"presentes\": ids\n",
        "    }\n",
        "\n",
        "def _pick_dom(d):\n",
        "    if not d: return \"\"\n",
        "    return max(d.items(), key=lambda kv: kv[1])[0]\n",
        "\n",
        "\n",
        "\n",
        "def sugerir_suportes(ids):\n",
        "    metas = [safe_meta(x) for x in ids]\n",
        "    def has(pred): return any(pred(m) for m in metas)\n",
        "    out = []\n",
        "    if has(lambda m: \"liberar_emocoes\" in (m.get(\"funcoes\") or []) or \"expressao\" in (m.get(\"funcoes\") or [])): out.append(\"Dampiera\")\n",
        "    if has(lambda m: \"Ch2\" in (m.get(\"chakras\") or []) or \"sexual\" in (m.get(\"funcoes\") or [])): out.append(\"Macrozamia\")\n",
        "    if has(lambda m: \"memorias_dolorosas\" in (m.get(\"funcoes\") or [])): out.append(\"Illyarrie\")\n",
        "    if has(lambda m: \"solucoes_criativas\" in (m.get(\"funcoes\") or [])): out.append(\"Star of Bethlehem\")\n",
        "    if has(lambda m: \"renascimento\" in (m.get(\"funcoes\") or []) and \"trauma\" in (m.get(\"funcoes\") or [])): out.append(\"Menzies Banksia\")\n",
        "    if has(lambda m: \"pavor_morte\" in (m.get(\"funcoes\") or [])): out.append(\"Ribbon Pea\")\n",
        "    seen=set(); res=[]\n",
        "    for x in out:\n",
        "        if x not in seen:\n",
        "            res.append(x); seen.add(x)\n",
        "        if len(res)>=2: break\n",
        "    return res\n",
        "\n",
        "def _frase_direcao(m_pos, m_neg):\n",
        "    if m_pos[\"I_C1\"]>0: return \"Há direção de propósito ativa nas escolhas.\"\n",
        "    if m_neg[\"I_C1\"]>0: return \"Propósito aparece com resistência ou baixa consciência.\"\n",
        "    return \"A direção de propósito não aparece entre as principais escolhas.\"\n",
        "\n",
        "def _frase_gargalo(m_pos, m_neg):\n",
        "    if m_pos[\"I_C2\"]>=2 and m_pos[\"I_C3\"]>=2: return \"Feridas e defesas operam juntas e explicam atrito no cotidiano.\"\n",
        "    if m_pos[\"I_C2\"]>=2: return \"Feridas ativas pedem espaço de acolhimento antes de ajustes de padrão.\"\n",
        "    if m_pos[\"I_C3\"]>=3: return \"Padrões de rigidez e controle dominam a adaptação.\"\n",
        "    if m_pos[\"I_C5\"]>=1: return \"Há sinais de cansaço energético que exigem cadência.\"\n",
        "    return \"\"\n",
        "\n",
        "def _frase_relacional(ids_pos):\n",
        "    kpos = sum(1 for eid in ids_pos if safe_meta(eid).get(\"familia\",\"\")==\"Kangaroo Paw\")\n",
        "    if kpos>=2: return \"Relações estão no centro: pedem refinamento de presença e escuta.\"\n",
        "    if kpos==1: return \"Relações pedem pequenos ajustes de ritmo e comunicação.\"\n",
        "    return \"\"\n",
        "\n",
        "def _frase_energia(m_pos, m_neg):\n",
        "    if m_pos[\"IE\"]>=2: return \"Primeiro passo é estabilizar o ritmo para recuperar energia.\"\n",
        "    if m_pos[\"I_C5\"]>=1: return \"Sinais de oscilação energética aparecem e merecem atenção.\"\n",
        "    if m_neg[\"I_C5\"]>=1: return \"Reconhecer limites energéticos reduz atrito oculto.\"\n",
        "    return \"\"\n",
        "\n",
        "def _frase_cor(m_pos):\n",
        "    dom = _pick_dom(m_pos[\"cores\"]);\n",
        "    if not dom: return \"\"\n",
        "    zeros = [c for c in [\"Amarelo\",\"Azul\",\"Vermelho\",\"Verde\",\"Rosa\",\"Violeta\",\"Laranja\",\"Branco\",\"Preto\"] if m_pos[\"cores\"].get(c,0)==0]\n",
        "    if len(zeros)>=3: return f\"Predomínio cromático em {dom}. Falta contraste funcional em outras qualidades.\"\n",
        "    return f\"Predomínio cromático em {dom}.\"\n",
        "\n",
        "def _frase_chakra(m_pos):\n",
        "    dom = _pick_dom(m_pos[\"chakras\"])\n",
        "    return f\"Hotspot energético em {dom}.\" if dom else \"\"\n",
        "\n",
        "def _frase_resistencia(m_neg, ids_neg):\n",
        "    msgs = []\n",
        "    if m_neg[\"I_C1\"]>=1: msgs.append(\"Resistência em declarar ou sustentar propósito (C1).\")\n",
        "    if m_neg[\"I_C2\"]>=2: msgs.append(\"Resistência em tocar feridas/choques (C2).\")\n",
        "    if m_neg[\"I_C3\"]>=2: msgs.append(\"Resistência em flexibilizar padrões (C3).\")\n",
        "    if m_neg[\"I_C5\"]>=1: msgs.append(\"Resistência em reconhecer cansaço e limites (C5).\")\n",
        "    kneg = sum(1 for eid in ids_neg if safe_meta(eid).get(\"familia\",\"\")==\"Kangaroo Paw\")\n",
        "    if kneg>=1: msgs.append(\"Resistência relacional ativa (escuta/presença).\")\n",
        "    return \" \".join(msgs)\n",
        "\n",
        "def _sequencia(m_pos, m_neg):\n",
        "    if m_pos[\"IE\"]>=2 or m_neg[\"I_C5\"]>=1:\n",
        "        return [\n",
        "            \"Cadencie sono e tarefas por 7 dias (ritmo > volume).\",\n",
        "            \"Diário de energia: 2 anotações/dia sobre picos e quedas.\",\n",
        "            \"Ajuste 1 hábito de recuperação rápida após esforço.\"\n",
        "        ]\n",
        "    if (m_pos[\"I_C2\"]>=2 and m_pos[\"I_C3\"]>=2) or (m_neg[\"I_C2\"]>=2 and m_neg[\"I_C3\"]>=1):\n",
        "        return [\n",
        "            \"Nomeie 1 ferida recorrente que aciona defesa típica.\",\n",
        "            \"Pratique um gesto de flexibilização quando o gatilho surgir.\",\n",
        "            \"Registre um micro-avanço semanal de escolha consciente.\"\n",
        "        ]\n",
        "    return [\n",
        "        \"Defina uma intenção simples para os próximos 7 dias.\",\n",
        "        \"Observe onde surge atrito e descreva o contexto.\",\n",
        "        \"Escolha um ajuste pequeno e repita por 3 dias.\"\n",
        "    ]\n",
        "\n",
        "def _chakras_arquetipos_bloco(ids_pos, ids_neg):\n",
        "    def collect(ids):\n",
        "        ch, arq = {}, {}\n",
        "        for eid in ids:\n",
        "            m = safe_meta(eid)\n",
        "            for c in m.get(\"chakras\") or []:\n",
        "                ch[c] = ch.get(c,0)+1\n",
        "            for a in m.get(\"arquetipos\") or []:\n",
        "                arq[a] = arq.get(a,0)+1\n",
        "        return ch, arq\n",
        "    ch_pos, arq_pos = collect(ids_pos)\n",
        "    ch_neg, arq_neg = collect(ids_neg)\n",
        "    return {\n",
        "        \"chakras\": {\"positivos\": ch_pos, \"negativos\": ch_neg},\n",
        "        \"arquetipos\": {\"positivos\": arq_pos, \"negativos\": arq_neg},\n",
        "    }\n",
        "\n",
        "def _relatorio_texto(m_pos, m_neg, ids_pos, ids_neg):\n",
        "    blocos = [\n",
        "        _frase_direcao(m_pos, m_neg),\n",
        "        _frase_gargalo(m_pos, m_neg),\n",
        "        _frase_relacional(ids_pos),\n",
        "        _frase_energia(m_pos, m_neg),\n",
        "        _frase_cor(m_pos),\n",
        "        _frase_chakra(m_pos),\n",
        "        _frase_resistencia(m_neg, ids_neg),\n",
        "    ]\n",
        "    textoCliente = \" \".join([b for b in blocos if b]).strip()\n",
        "    textoPro = (\n",
        "        f\"Camadas(+): C1={m_pos['I_C1']} C2={m_pos['I_C2']} C3={m_pos['I_C3']} C4={m_pos['I_C4']} C5={m_pos['I_C5']}. \"\n",
        "        f\"Rel={m_pos['IR']} Prof={m_pos['IP']} Ene={m_pos['IE']}. \"\n",
        "        f\"Camadas(−): C1={m_neg['I_C1']} C2={m_neg['I_C2']} C3={m_neg['I_C3']} C4={m_neg['I_C4']} C5={m_neg['I_C5']}. \"\n",
        "        + textoCliente\n",
        "    ).strip()\n",
        "    return textoCliente, textoPro\n",
        "\n",
        "def interpret_selection_string_v7(selection_str: str) -> dict:\n",
        "    pairs = parse_selection(selection_str)\n",
        "    top7 = pairs[:7]  # Final = Top 7\n",
        "    ids_pos = [eid for eid, s in top7 if s>0]\n",
        "    ids_neg = [eid for eid, s in top7 if s<0]\n",
        "    m_pos = build_metrics(ids_pos)\n",
        "    m_neg = build_metrics(ids_neg)\n",
        "    textoCliente, textoPro = _relatorio_texto(m_pos, m_neg, ids_pos, ids_neg)\n",
        "    seq = _sequencia(m_pos, m_neg)\n",
        "    suportes = sugerir_suportes(ids_pos + ids_neg) or None\n",
        "    extra = _chakras_arquetipos_bloco(ids_pos, ids_neg)\n",
        "    return {\n",
        "        \"final\": {\n",
        "            \"resumo\": {\"textoCliente\": textoCliente, \"textoPro\": textoPro, \"sequencia\": seq, \"suportes\": suportes},\n",
        "            \"metricas\": {\"positivas\": m_pos, \"negativas\": m_neg},\n",
        "            \"ids\": {\"positivas\": ids_pos, \"negativas\": ids_neg},\n",
        "            \"chakras\": extra[\"chakras\"],\n",
        "            \"arquetipos\": extra[\"arquetipos\"],\n",
        "        },\n",
        "        \"parsed\": top7\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0677ed29",
      "metadata": {
        "id": "0677ed29"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Texto completo (v7.1 se disponível; fallback heurístico v6/v7.2) ===\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def _list_str(lst):\n",
        "    return \", \".join(lst) if lst else \"—\"\n",
        "\n",
        "def _fmt_camadas(cnt):\n",
        "    out = []\n",
        "    for c in [\"C1\",\"C2\",\"C3\",\"C4\",\"C5\"]:\n",
        "        out.append(f\"{c}={cnt.get(c,0)}\")\n",
        "    return \", \".join(out)\n",
        "\n",
        "# Preparos para heurística fallback\n",
        "pos_src = fin_pos_e if (fin_pos_e is not None and len(fin_pos_e)) else pre_pos_e\n",
        "neg_src = pd.concat([pre_neg_e, fin_neg_e], ignore_index=True) if (pre_neg_e is not None or fin_neg_e is not None) else None\n",
        "\n",
        "# Camadas\n",
        "cam_pos_cnt = Counter(pos_src[\"camada\"].dropna().astype(str)) if pos_src is not None and \"camada\" in pos_src.columns else Counter()\n",
        "cam_neg_cnt = Counter(neg_src[\"camada\"].dropna().astype(str)) if neg_src is not None and \"camada\" in neg_src.columns else Counter()\n",
        "\n",
        "# Domínios (+) com fallback por chakra\n",
        "def _infer_domain_row(row):\n",
        "    dval = str(row.get(\"dominio\",\"\")).strip().lower()\n",
        "    if dval:\n",
        "        if dval.startswith(\"rel\"): return \"Rel\"\n",
        "        if dval.startswith(\"prof\"): return \"Prof\"\n",
        "        if dval.startswith(\"ene\"): return \"Ene\"\n",
        "    ch = str(row.get(\"chakra\",\"\")).strip().lower()\n",
        "    if ch in {\"ch4\",\"4\"}: return \"Rel\"\n",
        "    if ch in {\"ch3\",\"3\",\"ch6\",\"6\"}: return \"Prof\"\n",
        "    if ch in {\"ch1\",\"1\",\"ch5\",\"5\"}: return \"Ene\"\n",
        "    return \"Prof\"\n",
        "\n",
        "if pos_src is not None and len(pos_src):\n",
        "    dom_series  = pos_src.apply(_infer_domain_row, axis=1)\n",
        "    dom_counts  = Counter(dom_series)\n",
        "else:\n",
        "    dom_counts  = Counter()\n",
        "\n",
        "def _color_line(df):\n",
        "    if df is None or df.empty or \"color\" not in df.columns:\n",
        "        return \"Cores(+): —\"\n",
        "    bucket = defaultdict(list)\n",
        "    for _, r in df.dropna(subset=[\"essence_name\"]).iterrows():\n",
        "        cor = str(r.get(\"color\",\"\")).strip().lower()\n",
        "        if not cor: continue\n",
        "        bucket[cor].append(str(r[\"essence_name\"]))\n",
        "    parts = []\n",
        "    for cor, names in sorted(bucket.items()):\n",
        "        uniq = sorted(set(names))\n",
        "        parts.append(f\"{cor}={len(uniq)} — {', '.join(uniq)}\")\n",
        "    return \"Cores(+): \" + \"; \".join(parts) + \".\"\n",
        "\n",
        "colors_line = _color_line(pos_src)\n",
        "\n",
        "def _counts_map(df, key_col, name_col):\n",
        "    m = defaultdict(list)\n",
        "    if df is None or df.empty: return m\n",
        "    g = df.dropna(subset=[key_col])[ [key_col, name_col] ].astype(str).groupby(key_col)\n",
        "    for k, sub in g:\n",
        "        m[str(k)] = sorted(sub[name_col].unique().tolist())\n",
        "    return m\n",
        "\n",
        "chak_pos_map = _counts_map(pos_src, \"chakra\", \"essence_name\") if pos_src is not None else {}\n",
        "chak_neg_map = _counts_map(neg_src, \"chakra\", \"essence_name\") if neg_src is not None else {}\n",
        "chak_pos_line = \"; \".join([f\"{k}×{len(v)} — {', '.join(v)}\" for k,v in chak_pos_map.items()]) if chak_pos_map else \"—\"\n",
        "chak_neg_line = \"; \".join([f\"{k}×{len(v)} — {', '.join(v)}\" for k,v in chak_neg_map.items()]) if chak_neg_map else \"—\"\n",
        "chak_pos_cnt = {k: len(v) for k,v in chak_pos_map.items()}\n",
        "chak_neg_cnt = {k: len(v) for k,v in chak_neg_map.items()}\n",
        "chakra_hotspot_pos = max(chak_pos_cnt, key=chak_pos_cnt.get) if chak_pos_cnt else None\n",
        "chakra_hotspot_neg = max(chak_neg_cnt, key=chak_neg_cnt.get) if chak_neg_cnt else None\n",
        "hotspot_line  = \"Hotspot(+): \" + (str(chakra_hotspot_pos) if chakra_hotspot_pos else \"—\")\n",
        "if chakra_hotspot_neg: hotspot_line += f\"; Hotspot(−): {chakra_hotspot_neg}\"\n",
        "\n",
        "def _sem_arq(df):\n",
        "    if df is None or df.empty: return []\n",
        "    m = df[df[\"arquetipo\"].isna() | (df[\"arquetipo\"].astype(str).str.strip()==\"\")]\n",
        "    return sorted(m[\"essence_name\"].dropna().astype(str).unique().tolist())\n",
        "\n",
        "arq_pos_map  = _counts_map(pos_src, \"arquetipo\", \"essence_name\") if pos_src is not None else {}\n",
        "arq_neg_map  = _counts_map(neg_src, \"arquetipo\", \"essence_name\") if neg_src is not None else {}\n",
        "arq_pos_sem = _sem_arq(pos_src); arq_neg_sem = _sem_arq(neg_src)\n",
        "\n",
        "# Gargalo simples\n",
        "pre_pos_ct = len(pre_pos); kept = len(set(pre_pos[\"essence_id\"]) & set(final_pos[\"essence_id\"]))\n",
        "retencao = round(100*kept/max(1, pre_pos_ct), 2) if pre_pos_ct else None\n",
        "c5n, c3n, c4n = cam_neg_cnt.get(\"C5\",0), cam_neg_cnt.get(\"C3\",0), cam_neg_cnt.get(\"C4\",0)\n",
        "gargalo = None\n",
        "if c5n >= 2 or (retencao is not None and retencao < 50):\n",
        "    gargalo = \"energia primeiro\"\n",
        "elif c3n >= 2:\n",
        "    gargalo = \"foco cognitivo primeiro\"\n",
        "elif (c4n >= 1) and (chakra_hotspot_pos in {\"Ch4\",\"4\"}):\n",
        "    gargalo = \"relacional primeiro\"\n",
        "\n",
        "seq = []\n",
        "if   gargalo == \"energia primeiro\":\n",
        "    seq = [\"Cadenciar sono e tarefas por 7 dias (ritmo > volume).\",\"Diário de energia 2×/dia: pico/queda + contexto.\",\"Um hábito rápido de recuperação após esforço.\"]\n",
        "elif gargalo == \"foco cognitivo primeiro\":\n",
        "    seq = [\"Intenção única para 7 dias.\",\"Registrar atrito cognitivo e contexto.\",\"Fechar um tema antes de abrir outro.\"]\n",
        "elif gargalo == \"relacional primeiro\":\n",
        "    seq = [\"Micro-acordos de comunicação com 1 pessoa-chave.\",\"Check-in breve diário focado em impedimentos.\",\"Feedback curto ao final da semana.\"]\n",
        "else:\n",
        "    seq = [\"Cadenciar sono e tarefas por 7 dias (ritmo > volume).\",\"Diário de energia 2×/dia: pico/queda + contexto.\",\"Escolher 1 tema e concluir antes de abrir outro.\"]\n",
        "seq_lines = \"\\n\".join([f\"- {s}\" for s in seq])\n",
        "\n",
        "def suggest_supports():\n",
        "    if pos_src is None or pos_src.empty: return []\n",
        "    if chakra_hotspot_pos and \"chakra\" in pos_src.columns:\n",
        "        f = pos_src[pos_src[\"chakra\"].astype(str).str.lower() == str(chakra_hotspot_pos).lower()]\n",
        "        if len(f) == 0: f = pos_src\n",
        "    else:\n",
        "        f = pos_src\n",
        "    return sorted(f[\"essence_name\"].dropna().astype(str).unique().tolist())[:2]\n",
        "suportes = suggest_supports()\n",
        "\n",
        "camadas_pos_str = _fmt_camadas(cam_pos_cnt)\n",
        "camadas_neg_str = _fmt_camadas(cam_neg_cnt) if sum(cam_neg_cnt.values())>0 else \"C1=0, C2=0, C3=0, C4=0, C5=0\"\n",
        "gargalo_line = f\"Gargalo: {gargalo}.\" if gargalo else \"Gargalo: —.\"\n",
        "dom_line = f\"Domínios(+): Rel={dom_counts.get('Rel',0)} Prof={dom_counts.get('Prof',0)} Ene={dom_counts.get('Ene',0)}.\"\n",
        "\n",
        "# Heurístico base\n",
        "texto_heuristico = (\n",
        "f\"Cliente\\nPreparação suficiente para trabalhar o tema.\\n\\n\"\n",
        "f\"Profissional\\nCamadas(+): {camadas_pos_str}.\\n{dom_line}\\nCores(+): {colors_line}\\n\"\n",
        "f\"Camadas(−): {camadas_neg_str}.\\n{gargalo_line}\\n\\n\"\n",
        "f\"Chakras\\nAtivos (+): {chak_pos_line}\\nResistência (−): {chak_neg_line}\\n{hotspot_line}\\n\\n\"\n",
        "f\"Arquétipos\\nAtivos (+): \" + (\"; \".join([f\"{k}×{len(v)} — {', '.join(v)}\" for k,v in arq_pos_map.items()]) if arq_pos_map else \"—\") + \"\\n\"\n",
        "+ f\"Resistência (−): \" + (\"; \".join([f\"{k}×{len(v)} — {', '.join(v)}\" for k,v in arq_neg_map.items()]) if arq_neg_map else \"—\") + \"\\n\"\n",
        "+ f\"Sem arquétipo mapeado: \" + _list_str(sorted(set(arq_pos_sem + arq_neg_sem))) + \"\\n\\n\"\n",
        "+ \"Sequência\\n\" + seq_lines + \"\\n\\n\"\n",
        "+ \"Suportes\\n\" + (_list_str(suportes) if suportes else \"Sem obrigatório; se desejar, 1 essência do final como guia.\")\n",
        ")\n",
        "\n",
        "# v7.1 path: usar helper interpret_selection_string_v7 se existir\n",
        "texto_final = None\n",
        "if TEXT_MODE == \"v7_1\" or \"interpret_selection_string_v7\" in globals():\n",
        "    try:\n",
        "        sel = (fin.iloc[0][\"selection\"] if len(fin) else (pre.iloc[0][\"selection\"] if len(pre) else \"\"))\n",
        "        if sel:\n",
        "            out = interpret_selection_string_v7(sel)  # esperado na v7.1\n",
        "            # aceitar múltiplos formatos de retorno\n",
        "            if isinstance(out, str):\n",
        "                texto_final = out\n",
        "            elif isinstance(out, dict):\n",
        "                # tentar o esquema final.resumo\n",
        "                try:\n",
        "                    resumo = out.get(\"final\", out).get(\"resumo\", out.get(\"resumo\", {}))\n",
        "                    tc = resumo.get(\"textoCliente\",\"\")\n",
        "                    tp = resumo.get(\"textoPro\",\"\")\n",
        "                    seqL = resumo.get(\"sequencia\", [])\n",
        "                    supL = resumo.get(\"suportes\", [])\n",
        "                    texto_final = (\n",
        "                        \"Cliente\\n\" + (tc or \"—\") + \"\\n\\n\"\n",
        "                        \"Profissional\\n\" + (tp or \"—\") + \"\\n\\n\"\n",
        "                        \"Sequência\\n\" + (\"\\n\".join([f\"- {s}\" for s in seqL]) if seqL else \"—\") + \"\\n\\n\"\n",
        "                        \"Suportes\\n\" + (\", \".join(supL) if supL else \"—\")\n",
        "                    )\n",
        "                except Exception:\n",
        "                    # tentar chave 'texto'\n",
        "                    texto_final = str(out.get(\"texto\",\"\"))\n",
        "    except Exception as e:\n",
        "        texto_final = None  # cai no heurístico\n",
        "\n",
        "if not texto_final:\n",
        "    # usar heurístico completo\n",
        "    texto_final = texto_heuristico\n",
        "\n",
        "text_df = pd.DataFrame([{\"texto\": texto_final}])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb1dbdb",
      "metadata": {
        "id": "eeb1dbdb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Auxiliares (temporal/produto/resumo) ===\n",
        "d2 = raw[raw[\"session_effective\"]==SESS].copy()\n",
        "if \"timestamp_local\" in d2.columns: d2 = d2.sort_values(\"timestamp_local\")\n",
        "\n",
        "temporal_cols = [\"timestamp_local\",\"kind\",\"subject\",\"action\",\"triggerKind\",\"option\",\"price\",\"currency\",\"payment_status\",\"event_id\",\"event_id_linked\",\"hp\",\"locale\",\"ip_address\",\"referer\"]\n",
        "REL_temporal = d2[[c for c in temporal_cols if c in d2.columns]].copy()\n",
        "\n",
        "prod_cols = [\"action\",\"triggerKind\",\"option\",\"price\",\"currency\",\"payment_status\",\"product_id\",\"stripe_customer_id\",\"stripe_payment_intent_id\"]\n",
        "if len(d2): REL_produto = d2.tail(1)[[c for c in prod_cols if c in d2.columns]].copy()\n",
        "else:       REL_produto = pd.DataFrame(columns=prod_cols)\n",
        "\n",
        "kept = len(set(pre_pos[\"essence_id\"]) & set(final_pos[\"essence_id\"]))\n",
        "new_final = len(set(final_pos[\"essence_id\"]) - set(pre_pos[\"essence_id\"]))\n",
        "drop = len(set(pre_pos[\"essence_id\"]) - set(final_pos[\"essence_id\"]))\n",
        "conv_neg_to_pos = len(set(pre_neg[\"essence_id\"]) & set(final_pos[\"essence_id\"]))\n",
        "persist_neg = len(set(pre_neg[\"essence_id\"]) & set(final_neg[\"essence_id\"]))\n",
        "REL_resumo = pd.DataFrame([\n",
        "    {\"metric\":\"pre_pos\",\"value\":len(pre_pos)},\n",
        "    {\"metric\":\"pre_neg\",\"value\":len(pre_neg)},\n",
        "    {\"metric\":\"final_pos\",\"value\":len(final_pos)},\n",
        "    {\"metric\":\"final_neg\",\"value\":len(final_neg)},\n",
        "    {\"metric\":\"retencao_positivos\",\"value\": round(100*kept/max(1, len(pre_pos)),2) if len(pre_pos)>0 else None},\n",
        "    {\"metric\":\"novos_positivos\",\"value\": new_final},\n",
        "    {\"metric\":\"+_para_-\",\"value\": drop},\n",
        "    {\"metric\":\"-_para_+\",\"value\": conv_neg_to_pos},\n",
        "    {\"metric\":\"negativos_persistentes\",\"value\": persist_neg},\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d91617",
      "metadata": {
        "id": "c2d91617"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Gravação ===\n",
        "# Sempre grava texto e detalhes\n",
        "write_tab(ss_out, TAB_TEXT, text_df)\n",
        "write_tab(ss_out, TAB_DET_ALL, det_all)\n",
        "\n",
        "if not TEXT_ONLY:\n",
        "    write_tab(ss_out, TAB_DET_PRE_POS, pre_pos_e)\n",
        "    write_tab(ss_out, TAB_DET_PRE_NEG, pre_neg_e)\n",
        "    write_tab(ss_out, TAB_DET_FIN_POS, fin_pos_e)\n",
        "    write_tab(ss_out, TAB_DET_FIN_NEG, fin_neg_e)\n",
        "\n",
        "    write_tab(ss_out, TAB_OVERVIEW, overview)\n",
        "    write_tab(ss_out, TAB_PRE_POS, pre_pos)\n",
        "    write_tab(ss_out, TAB_PRE_NEG, pre_neg)\n",
        "    write_tab(ss_out, TAB_FINAL_POS, final_pos)\n",
        "    write_tab(ss_out, TAB_FINAL_NEG, final_neg)\n",
        "    write_tab(ss_out, TAB_MOVEMENT, movement)\n",
        "    write_tab(ss_out, TAB_COMPARATIVO, comparativo)\n",
        "    write_tab(ss_out, TAB_RESUMO, REL_resumo)\n",
        "    write_tab(ss_out, TAB_TEMPORAL, REL_temporal)\n",
        "    write_tab(ss_out, TAB_PRODUTO, REL_produto)\n",
        "    write_tab(ss_out, TAB_ATTRS, REL_ATTRS)\n",
        "    write_tab(ss_out, TAB_ATTRS_STAGE, REL_ATTRS_STAGE)\n",
        "\n",
        "print(\"Concluído v7.3.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}